# Brazilian Soccer Championship Analysis
## Summary
> O que Ã©
> 
> O que foi usado (ferramentas e conceitos)
>
> FunÃ§Ãµes de cada um no projeto

This project aims to analyze the Brazilian Soccer Championship, also known as "BrasileirÃ£o", which is the top-tier professional football league in Brazil. The analysis is based on the historical data of the championship, including match results, player statistics, and other relevant factors.

The project was divided into 3 steps:

1. Data Selection
2. Data Manipulation
3. Data Analysis and Vizualization

<br>


# 1. Data Selection <br>
The first step consisted of selecting the datasets to be used in the project. The ones we choose are available [here](https://www.kaggle.com/datasets/adaoduque/campeonato-brasileiro-de-futebol).
After the dataset was selected, it was loaded into Google Sheets for a preliminary verification of data quality and to ensure uniform formatting.

With the initials adjustments done, the tables were lodaded into BigQuery as "raw" tables (bronze layer) to begin the massive transformations.

<br>

# 2. Data Manipulation <br>
In the second step, our objective was to build a data warehouse architecture and model all the raw data that had been extracted. The structure was designed based on 3 data marts.

- The main data mart stores the data about events in each match. It comprises a transactional table named `factEvents` and five additional dimensions: `dimMatch`, `dimPlayer`, `dimArena`, `dimTeam` and `dimCalendar`.
- The second data mart contains data regarding match statistics, with a central table named `factStatistics` that relates to `dimTeam` and `dimMatch`.
- The third and final data mart records the final score table for each year and the main table `factScore` is also related to `dimTeam`.

Subsequently, the ETL process as well as the final tables will be presented in a detailed manner below.

![](datamodel_picture.png)
*ERD of brasileirao championship data model*

<br>

The entire model is represented [here](https://drive.google.com/file/d/1ejlKub_w4EP8wMyLYU0ykyO7PT3yaIc9/view?usp=sharing).


### ETL process
After the completion of the extraction phase, the data transformation step was initiated. For this stage, an ETL process was developed using SQL to establish the data warehousing solution. Given the structure of the raw data, the dimensional modeling "star schema" was chosen as the optimal option to address the business questions.

For data storage and the execution of all transformation steps, the BigQuery platform was employed. Within BigQuery, three layers were created to process the data according to the phase and data application.

ğŸ‘‰ **Bronze layer**: This layer contains raw tables from Google Sheets files.

ğŸ‘‰ **Silver layer**: This layer contains two intermediary tables used specifically on the `dimPlayer` creation process.

ğŸ‘‰ **Gold layer**: This layer contains the final data warehouse tables (fact-s and dimÂ´s) with curated data ready to be used.

@TODO [UM DESENHO DO PROCESSO DE ETL]

@TODO [FALAR SOBRE OS ACESSOS AO BIGQUERY - TABELAS DO DW E QUERIES]

### Data model
As mentioned earlier, the model consists of 3 fact tables and 5 dimensional tables that are related to each other through a star schema modeling across 3 data marts. Subsequently, a detailed explanation of each table stored in the data warehouse will follow.

âš½ `dimMatch`:

ğŸƒğŸ½â€â™‚ï¸ `dimPlayer`:

ğŸŸ `dimArena`:

ğŸ›¡ `dimTeam`:

ğŸ“… `dimCalendar`:

ğŸ¥… `factEvents`:

ğŸ”¢ `factStatistics`:

ğŸ… `factScore`:

- Explicar sobre os tipos de scd utilizados
    - dimTime - a partir da tabela brasileiro_full e do os idÂ´s de partidas como sat_id e end_id
    - dimJogador - a partir das tabelas de stg, que por sua vez utilizaram as tabelas de eventos e gols. PorÃ©m, como apenas a tabela de eventos possuÃ­a posiÃ§Ã£o e nÂº da camisa, o scd criado utilizado como end_id, o valor de start_id-1 (subtraÃ§Ã£o) da linha seguinte


<br>


# 3. Data Analysis and Vizualization
Na terceira etapa do projeto foi feita anÃ¡lises dos dados sobre o brasileirÃ£o utilizando o modelo de dados criado na etapa anterior.

Para tal, foram levantadas hipÃ³teses e, utilizando o modelo de dados, estas hipÃ³teses foram validadas possuindo como resultado sua confirmaÃ§Ã£o ou sua rejeiÃ§Ã£o, ou seja, foi verificado se cada afirmaÃ§Ã£o Ã© verdadeira ou falsa.

Das hipÃ³teses analisadas se destacam as seguintes afirmaÃ§Ãµes:
  
- ğŸ“Œ *Times mandantes ganham com mais frequÃªncia*
- ğŸ“Œ *Times mandantes tomam menos cartÃµes* 
- ğŸ“Œ *Times com jogador expulso no primeiro tempo perdem o jogo com mais frequÃªncia*
- ğŸ“Œ *O 2Âº turno do campeonato (rodada 29 em diante) tende a exibir partidas com mais eventos (gols e cartÃµes)*
- ğŸ“Œ *Times campeÃµes tem maior precisÃ£o de passe*

Para realizar as anÃ¡lises propostas foi utilizado o Google Colab como ferramenta de processamento e visualizaÃ§Ã£o, utilizando Python como linguagem e fazendo a conexÃ£o com o BigQuery diretamente.

> ğŸ“˜ **O _Google Colab_ foi escolhido por ser a Ãºnica ferramenta gratuita que possibilita a fÃ¡cil conexÃ£o entre seus notebooks e o BigQuery, sendo o Ãºltimo onde o modelo de dados estÃ¡**

Abaixo estÃ£o os notebooks utilizados:

- [Times mandantes ganham com mais frequÃªncia](https://github.com/igoravelli/brazilian_soccer_championship_analysis/blob/readme-file/Win_frequency_in_home_matches.ipynb)
- [Times mandantes tomam menos cartÃµes](https://github.com/igoravelli/brazilian_soccer_championship_analysis/blob/main/Average_of_cards_in_home_team_matches.ipynb)
- [Times com jogador expulso no primeiro tempo perdem o jogo com mais frequÃªncia](https://github.com/igoravelli/brazilian_soccer_championship_analysis/blob/main/Number_of_matches_with_expelled_players.ipynb)
- [Times campeÃµes tem maior precisÃ£o de passe](https://github.com/igoravelli/brazilian_soccer_championship_analysis/blob/main/Teams_accuracy_pass.ipynb)
- [O 2 turno do campeonato (rodada 29 em diante) tende a exibir partidas com mais eventos (gols e cartÃµes)](https://github.com/igoravelli/brazilian_soccer_championship_analysis/blob/main/Events_frequency_along_the_turns_.ipynb)


â© Ao final de cada notebook estÃ£o conclusÃµes sobre a anÃ¡lise feita

<br>

AlÃ©m dessas hipÃ³teses tambÃ©m foi proposto o seguinte questionamento:
> ğŸ“¢ Em qual faixa do tempo os gols da vitÃ³ria (ou todos os gols) sÃ£o marcados para cada time? Esse perfil muda quando a vitÃ³ria Ã© de um mandante ou de um visitante?
> 
> ğŸ” [notebook com a anÃ¡lise](https://github.com/igoravelli/brazilian_soccer_championship_analysis/blob/main/Goal_scoring_distribution_by_team.ipynb)
>
> Como conclusÃ£o temos a distribuiÃ§Ã£o dos gols de cada time pelo minuto da partida, o que nos da uma visÃ£o sobre o momento da partida onde cada time marcou gols no ano de 2014
> 
> ![](goal_score_distribuition.png)
> *distribuiÃ§Ã£o dos gols pelo minuto da partida para cada time*

<br>

# References
KIMBALL, Ralph. The data warehouse toolkit: practical techniques for building dimensional data warehouses. John Wiley & Sons, Inc., 1996.

MUNZNER, Tamara et al. Exploratory data analysis.

Google Cloud. (2023). Google BigQuery Documentation. Retrieved from (https://cloud.google.com/bigquery/docs)

Google. (2023). Google Colab Documentation. Retrieved from (https://colab.research.google.com/notebooks/intro.ipynb)